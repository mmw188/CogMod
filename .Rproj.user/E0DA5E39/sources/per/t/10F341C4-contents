---
title: 'Duolingo SLAM dta'
author: '[Matthew Walsh]'
dte: January 2020
output:
  html_document:
    toc: yes
    df_print: paged
  html_notebook:
    toc: yes
  pdf_document:
    toc: yes
---


# Introduction
Duolingo is a free online language-learning platform. Since launching in 2012, hundres of millions of learners worldwide have enrolled in Duolingo’s courses either via the website or mobile apps.

Online platforms like Duolingo have recently been used to create massive datasets drawn from diverse learners who complete activities in a self-paced manner, on personal devices, and at their preferred times and locations. These data create a unique opportunity to validate and extend computational cognitive models of knowledge acquisition and retention.

In this notebook, I fit the Predictive Performance Equation (PPE) to a large sample of data gathered from Duolingo. This provides a novel test of PPE using a large dataset gathered in naturalistic conditions.

### The Predictive Performance Equation (PPE)
For more than a century, psychologists have conducted experiments to identify factors that impact the acquisition and retention of knowledge. These studies have revealed that the acquisition and retention of knowledge is impacted by at least three primary factors.

1. Amount of practice. Performance improves with the number of previous practice repetitions.
2. Elapsed time since practice. Performance decreases with the elapsed time since practice occured.
3. Temporal distribution of practice. Increasing the amount of time, or 'spacing' between practice repetitions increases retention.

PPE is a computational cognitive model of skill acquisition and retention. PPE is made up of a series of equations, implemented as a running computer simulation, that account for how amount of practice, elapsed time since practice occured, and the distribution of practice over time affects knowledge acquisition and retention.

### Duolingo SLAM
The Second Language Acquisition Modeling (SLAM) dataset contains over 2 million words and answers from over 6,000 students during their first 30 days of using Duolingo in 2018. Students were from three language tracks: native French speakers learning English, native Spanish speakers learning English, and native English speakers learning Spanish. Students answered three types of questions: translate required translating a word from one’s native language (L1) to the second language (L2); select required selecting the correct translation from a word bank; and listen required translating a spoken word from L2 to L1. All questions involved a single vocabulary item. SLAM contains student- and item-level information on study history and performance (i.e., response accuracy), as well as metadata descriptors including question format, language, and part of speech.

Aside from providing a test of basic principles of memory and cognition, SLAM offers a unique opportunity to validate PPE using a diverse sample of individuals learning in naturalistic conditions.

```{r include = FALSE, message=FALSE, warning=FALSE}
library(tidyr)
library(tidyverse)
library(RColorBrewer)
library(patchwork)
library(dplyr)
library(data.table)
library(parallel)

util.dir <- './utilities'
sapply(file.path(util.dir, list.files(util.dir)), source)

input.dir  <- 'inputs'

df <- read_csv(file.path(input.dir, 'subset_SLAM_data.csv'))

df <- df %>%
  mutate(time_diff = ifelse(repetition == 1, 1000, time_diff),
         lag       = time_diff,
         first     = 0)

df.first <- filter(df, repetition == 1) %>%
  mutate(time        = time - 1000,
         repetition  = 0,
         time_diff   = NA,
         lag         = NA,
         performance = NA,
         first       = 1)

df <- bind_rows(df.first, df) %>%
  arrange(user_id, stimulus_id, repetition) %>%
  mutate(repetition = repetition + 1)

df <- setDT(df)

# Calculate model stability
df[ , stability := get_stability(time),
    by = c('user_id', 'stimulus_id')]

# Calculate model time
x <- 0.6
df[ , model.time := get_model_time(time, x),
    by = c('user_id', 'stimulus_id')]

# Calculate score
df[ , score := ifelse(repetition > 1, performance, NA_integer_)]
df[ , performance_num := as.numeric(performance)]
write.csv(df, file.path(input.dir, 'ppe_SLAM_data.csv'), row.names = FALSE)
```

# Model Evaluation

### Methods
For each learner in SLAM, I gave PPE the exact study history by item and time. I then used a maximum likelihood approach to estimate PPE parameter values to best account for observed performance. I fitted the model separately by language track to account for differences in learning and forgetting by language,

```{r include = FALSE, message=FALSE, warning=FALSE}
## 3. Model fits (language by format)
## 3.1 Fit

if (file.exists(file.path(input.dir, 'ModelParameters.RDS'))){
  mp <- readRDS(file.path(input.dir, 'ModelParameters.RDS'))
} else {
  params <- list(b = 0, m = .1, tau.1 = .4, tau.2 = .4, tau.3 = .4, s = .2)
  
  mp <- mclapply(unique(df$language),
               function(x) {
                 output <- fit_ppe_vary_tau(filter(df, language == x), params, 'log_likelihood')
                 output$language <- x
                 return(output)
               }
               )
  
  mp <- bind_rows(mp)
  saveRDS(mp, file.path(input.dir, 'ModelParameters.RDS'))
}
```

### Effects of Repetitions on Performance
A fundamental finding from learning science research is that performance improves with the amount of practice. The curves marked “Observed” in Figure 1 show how the average user’s response accuracy changed based on the number of times they had studied the word. The curves marked “Model” represent the outputs of the cognitive model, PPE.

Observed accuracy increased with amount of practice; initial practice produced the largest gains, and subsequent practice produced additional gains but at a diminishing rate. Accuracy also varied by question type; it was higher for questions that involved recognizing the correct translation from an answer bank relative to questions that involved generating correct translations from memory. Finally, accuracy varied by language track; it was lower for native French speakers learning English relative to the other tracks. PPE accounted for these effects.

```{r include = FALSE, message=FALSE, warning=FALSE}
df.pred <- left_join(df, mp, by = 'language') %>%
  mutate(tau = case_when(format == 'Listen'    ~ tau.1,
                         format == 'Select'    ~ tau.2,
                         format == 'Translate' ~ tau.3),
         ppe_pred_format = pred.ppe.tau(tau, repetition, model.time, b, m, stability, s),
         repetition = repetition - 1)

## 3.3 Plot learning
perf_avg <- df.pred %>%
  mutate(repetition = ifelse(repetition >= 20, 20, repetition)) %>%
  group_by(user_id, language, repetition, format) %>%
  summarise(Observed = mean(performance),
            Model  = mean(ppe_pred_format)) %>%
  group_by(language, repetition, format) %>%
  summarise(se = sqrt(var(Observed)/n()),
            Observed = mean(Observed),
            se.predict = sqrt(var(Model)/n()),
            Model = mean(Model))

perf_avg <- gather(perf_avg %>% select(language, repetition, format, Observed, Model), key = 'Outcome', value = 'Accuracy', c('Observed', 'Model'))
p1 <- lapply(c('Listen', 'Select', 'Translate'),
             function(x) plot.learning(x, perf_avg))
             
p1 <- p1[[1]] / p1[[2]] / p1[[3]] + plot_layout(guides = 'collect') & theme(legend.position = 'bottom')
```

```{r fig.cap = 'Figure 1. Performance based on language, prompt type, and number of repetitions', fig.width = 6.5, fig.height = 6.5, fig.fullwidth = TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
p1
```

### Effects of Lag on Performance
Another fundamental finding from learning science research is that performance decreases with elapsed time since practice occurred. In SLAM, the elapsed time since previous exposure to a word is a continuously varying value. To visualize the data, we combined elapsed times into bins ranging from minutes, to hours, to days, as displayed in Figure 2. The solid lines marked “Observed” show how the average user’s response accuracy changed based on the elapsed time since they had last studied the word. Accuracy decreased with the length of the retention interval and varied by question type and language. PPE accounted for these effects

```{r include = FALSE, message=FALSE, warning=FALSE}
df.pred$lag_cat <- factor(df$lag_cat, levels = c('0 to 90 sec', '90 sec to 1 hr', '1 hr to 1 day', '1 to 2 days', '2 to 3 days', '>3 days', 'First rep'))

ret_avg <- df.pred %>%
  filter(repetition > 1) %>%
  group_by(user_id, language, lag_cat, format) %>%
  summarise(Observed = mean(performance, na.rm = TRUE),
            Model  = mean(ppe_pred_format)) %>%
  group_by(language, lag_cat, format) %>%
  summarise(se = sqrt(var(Observed)/n()),
            Observed = mean(Observed),
            se.predict = sqrt(var(Model)/n()),
            Model = mean(Model)) %>%
  mutate(x.val = as.numeric(lag_cat))

ret_avg <- gather(ret_avg %>% select(language, lag_cat, x.val, format, Observed, Model), key = 'Outcome', value = 'Accuracy', c('Observed', 'Model'))

p2 <- lapply(c('Listen', 'Select', 'Translate'),
             function(x) plot.retention(x, ret_avg))

p2 <- p2[[1]] / p2[[2]] / p2[[3]]  + plot_layout(guides = 'collect') & theme(legend.position = 'bottom')
```

```{r fig.cap = 'Figure 2. Performance based on language, prompt type, and time since last repetition', fig.width = 6.5, fig.height = 6.5, fig.fullwidth = TRUE, message = FALSE, warnings = FALSE, echo = FALSE, results='hide'}
p2
```